---
layout:      post
title:       "读书笔记：《软件定义网络：SDN与OpenFlow解析》"
subtitle:    "Software Defined Network and OpenFlow protocol"
author:      "Ashior"
header-img:  "img/ReadNotes/bg-SDN核心技术剖析和实战指南.jpg"
catalog:     true
tags:
  - OpenFlow
  - SDN
  - 读书笔记
---

> 这本书是翻译版本，读起来非常费力，同时本身写的偏向于网络底层路由，读者量力而读吧。笔者读这本也只是为SDN相关实验做铺垫。
> 回头看，这本书写的是真的菜啊，都是一些名词堆砌，发现好多书都是如此。或许现在能够理解，为什么想要某个东西，最好的方式就是去阅读他的相关文献。主要是阅读文献太费时费力了。根据我目前的需求与时间来说，还是看书吧，更加系统与概述，主要是以了解为主。顺便预告一下，下一阶段的任务就是对FloodLight源码的阅读，其实更多的也是了解其执行过程。

## 阅读的基本条件

1. OSI模型：OSI（Open System Interconnection，开放式系统互联）通信参考模型定义了7个不同的网络层次：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。这个模型使得网络工程师和网络供应商能够方便地讨论，并将技术应用于特定的OSI 层。这种层次划分使得工程师可以将应用程序之间的通信这一整体问题分解成单独并且更加便于管理的部分。每一层都有特定的属性，每一层与它相邻的层都以一种非常明确的方式交互。
2. 交换机：这种设备在OSI模型的第2层工作，并且采用逻辑上的本地寻址来传输网络帧。这类设备包括了以太网和它所有的变种，VLAN、汇聚和冗余设备。
3. 路由器：这些设备工作在OSI模型的第3层，彼此将多个IP子网连接起来。路由器以逐跳的方式来传输网络包。
4. 以太网：这些广播域将多个主机连接到一个共用基础设施上。主机之间的通信采用第2层的MAC（Media Access Control，媒体访问控制）地址。
5. IP地址和子网：主机之间使用32位的地址通过IP协议进行通信。人们经常采用点分隔的十进制数值格式来表示这些地址。这种地址标记包括了网络地址和主机地址两个部分，一般看上去是这样的：192.168.1.1/24。
6. TCP和UDP：这些第4层的协议定义了主机之间通信的方法。TCP（Transmission Control Protocol， 传输控制协议） 提供了面向连接的通信， 而UDP（User Datagram Protocol，用户数据报协议）则使用无连接的模式通信。使用TCP还有流量控制、窗口/ 缓存和显式确认等好处。
7. ICMP：作为（某些平台上）ping和traceroute程序所使用的核心协议，网络工程师使用它对网络进行诊断和操作。另外ICMP（Internet Control Messages Protocol，网际控制报文协议）还被用于发于IP网的主机间的出错信号和其他消息。
8. 数据中心：用于放置大量计算机系统和相关组件（例如电信和存储系统）的场所。数据中心通常要有冗余或备用电源、冗余的数据通信连接、环境控制（如空调和消防）设施和安全设备。大型数据中心作为一种工业级基础设施，消耗的电力可以相当于一个小城镇。
9. MPLS：MPLS（Multiprotocol Label Switching，多协议标签交换）是一种在高性能网络中使用的机制，它可以根据短路径标签而非长网络地址将数据报文从一个网络节点传输到另一个节点，以避免在路由表中进行复杂的查找。这些标签标识了远端节点之间而非端点之间的虚拟链路（路径）。MPLS可以封装多种网络协议的数据包，并且支持多种接入技术。
10. 北向接口（Northbound Interface）：
将组件所使用的或组件中的底层细节（如数据或函数）抽象化的接口。通过它可以和采用上层组南向接口的上层组件交互。从总体架构来看，北向接口一般画在定义它的组件的顶部，因此称为北向接口。北向接口的例子有JSON和Thrift。
11. 南向接口（Southbound Interface）：
与北向接口相反的接口。南向接口一般画在架构图的底部。南向接口的例子包括I2RS、NETCONF和命令行接口。
12. 网络拓扑：计算机网络中各个网元设备（链路、节点、接口、主机等）的布置。本质上，它是网络的拓扑结构，并且可以有物理或逻辑上的表现形式。物理拓扑结构指网络中各组件的摆放，包括设备的位置和线缆的安装，而逻辑拓扑显示了数据在网络中如何流动，与物理设计无关。就算两个网络的节点间距离、物理互联、传输速率或信号类型不同，它们的逻辑拓扑结构也可能是相同的。
13. API软件组件之间交互的规范说明。在实践中，API（Application Programming Interface，应用编程接口）通常是一个库，其中包括变量、程序、对象类和数据结构的规范。API 规范可以有多种表现形式，包括国际标准（如POSIX）、供应商文档（如JunOS SDK）或某种编程语言的库。

----

## 前言

软件定义网络（SDN）：是一种优化和简化网络操作的体系结构方式，它将应用与网络服务、设备之间的交互（如服务开通配置、消息传递、警报）更紧密地结合在一起，不论它们是物理的还是虚拟化的。它通常利用一个逻辑上集中式的网络控制，通常被认为是由SDN 控制器来实现，它编排、协调并促进希望与网元设备进行交互的应用程序，以及希望传送信息给应用的网元设备之间的通信。然后，控制器通过现代化的、应用友好的、双向的编程接口来展示、抽象网络功能和操作。

----

## 集中式与分布式的控制平面和数据平面

从高度抽象的角度来看，控制平面在本地建立了用于创建转发表项的数据集，数据平面利用转发表项在设备的出入端口之间转发流量。其中保存了网络拓扑的数据集被称为路由信息库（RIB）。在与网络中其他控制平面通信的过程中，RIB总是保持其一致性（如不会产生环路）。转发表项通常被称为转发信息库（FIB），并且一般在设备的控制和数据平面上保持镜像关系。一旦RIB被视为一致且稳定，FIB马上就会被创建出来。要执行此任务，控制实体/程序必须建立一个网络拓扑的视图（view），此视图必须满足一定的约束条件。

#### 数据平面

数据平面通过一系列链路层操作来处理（通过线缆、光纤或无线媒介）到来的数据分组。这些操作通常包括数据分组的收集和基本的完整性检查。数据平面通过查询由控制平面所编程的FIB表（在某些实现中，可能是多个FIB表）来处理一个格式正常的数据分组。这有时被称为数据处理的快速路径（fast path），因为它除了利用编程好的FIB识别数据分组的目的地址之外不需要额外的操作。

数据平面转发查找结果带来的典型操作就是转发（在特殊情况如组播下，此典型操作是复制）、丢弃、重标记、计数和排队。某些动作可以组合或者串连起来。在某些情况下，转发选路操作会返回一个设备内的本地端口，这表明流量被定向到一个在该设备内部运行的进程，比如OSPF或者BGP6。这些数据分组会采用被称为上传路径(punt path)的路径，即借以离开硬件转发路径，使用内部通信通道转发到本设备的路由处理器。这个路径通常是一条相对较低吞吐率的路径，这是因为它不是设计用来做正常流量的高吞吐率包转发用的；然而，为了高吞吐率，有的设计可以简单地在内部交换矩阵里增加一个额外通道，这样就能达到在设备内部接近线速转发的目的。

一个访问控制列表可以对某个特定的匹配流指定一个丢弃操作（注意，在ACL中，一个较宽泛的参数集合可以被用到转发选路中）。由于ACL也可以有合法的转发表项，所以数据分组不被丢弃。一个服务质量（QoS）策略最终把一个流映射到出口的一个队列，或者重标记它的TOS/COS字段来对网络策略的服务进行规格化。就像ACL，不管是否已经存在到这个目的/流的转发表项，它都可以将分组标记为丢弃（整形）。

#### 收敛

IP模式中的FIB（或者数据平面转发状态表项）已经经历了多年的软件设计与遍历（查找）算法的优化。在这个模式中，收敛和负载均衡对于网络运维人员/设计者就像前述的黑洞一样。**收敛**是指，从某个网元设备上由于网络事件而引起目的地可达性变化开始，到这个变化被所有其他网元设备都知道，并实际起作用为止，所花费的时间。可能对读者来说，最熟悉的收敛时间的某个组成部分，就是对某个更新的传播延迟。这通常是从最初发生变化的节点，到重泛洪/重传播的中间节点的跳数数量，来度量平均距离的关联函数。收敛的其他组成部分，将关注于本地更新过程，例如更新RIB的操作，以及在数据平面进行更新FIB等实际起作用的操作。

#### 负载均衡

分布式IP转发的负载均衡已从对逐包的处理，发展到对IP分组头更多部分进行哈希处理。这是因为越来越多的用于语音或者其他媒体18的不同数据流，开始被网关设备所处理。不过可能是为了某种目的的非等价路径，负载均衡通常被用于等价路径，或者捆绑的点到点电路。负载均衡算法的实际效率受限于计算的算法本身，以及可能会遇到的潜在的数据流大小的失衡。这会导致装箱效率问题（bin-packing efficiency problem）。在极端情况下，最终将导致等价路径的数量或者实现支持的绑定成员的数量方面的限制。

#### 集中式控制平面

集中式控制平面的主要优点是，它可以向应用程序提供网络视图和简化编程控制。为了实现一个大网中的端到端的改变，应用程序不再需要知道，或直接接触各个网元设备，而是与几个处理这些细节的控制点交互。

----

## OpenFlow

OpenFlow1.3的协议被分为两个部分：

1. 一个是线路协议（wire protocol，目前的版本是1.3.x），用于建立控制会话，它定义了用于对流的修改（flow mods）进行交互和对统计数据进行收集的消息结构，并定义了一个交换机（端口和流表）的基本结构。其1.1 版新增了支持多表（multiple table）、对动作执行进行暂存以及元数据传递功能，这些功能最终在交换机内创建了逻辑的流水线（pipeline）处理，用于处理流程。

2. 另一个是配置与管理协议of-config（当前的版本是1.1），它基于NETCONF（使用Yang数据模型）来给特定的控制器分配物理的交换机端口，并定义高可用性（主/备机制）和控制器连接失败时的行为。虽然OpenFlow 可以配置对OpenFlow 的命令/控制的基本操作，但它还不能启动或维护网元设备（即还不能达到FCAPS级的管理，FCAPS 即即故障、配置、计费、性能和安全）。
 
OpenFlow与分布式IP/MPLS模型相比，在运行者所能控制的广度上有着很明显的差异（OpenFlow有11元组的匹配空间）。下面简短地列出了控制广度的可能性。

1. 因为在OpenFlow匹配指令中的掩码能力，网络可以模拟基于IP目的地址的转发行为。
2. 在二层和三层上，网络都可以表现出基于源/目的的路由行为。
3. OpenFlow的数据分组匹配能力目前还没有其他标准能做到，这使其在替代策略路由或分布式控制环境中的其他匹配/转发机制方面非常强大。

OpenFlow协议通过EXPERIMENTER扩展（扩展可以是公共的，也可以是私有的）来实现对控制消息、流匹配字段、计量表操作、统计数据的扩展，以及厂商特定的扩展（这些扩展可以是公共的，也可以是私有的）。
表项可以有优先级（如果表项有重叠），并有时间到期机制（在某些情况下避免了清理操作，并对控制器丢失等情况下的流表项有终止效果）。
OpenFlow支持PHYSICAL、LOGICAL和RESERVED的端口类型（分别对应物理的、逻辑的和预留的端口类型）。这些端口被用作入口、出口或双向结构。预留的端口IN_PORT和ANY，IN_PORT 代表数据报文进入的端口，ANY 用在无需特别指定端口的情况下。

1. LOCAL仅用于出端口，该逻辑端口允许OpenFlow 的应用程序访问网元设备的主机操作系统的端口（进而访问进程）。
2. NORMAL仅用于出端口，该逻辑端口允许交换机像一个传统的以太网交换机（以及相关的洪泛/学习行为）那样运作。根据该协议功能规范，该端口仅在混合交换机中受支持。这里“混合”的原始定义是，一台交换机，既可作为OpenFlow交换机，也可（在OpenFlow 域里面的端口上）作为二层交换机。
3. FLOOD仅用于出端口，该逻辑端口使用网元设备的复制引擎来把数据分组发送到所有标准（非预留）端口。FLOOD与ALL（另外一个预留端口）不同，ALL端口包含入端口。FLOOD利用了网元设备的数据分组复制引擎。
4. CONTROLLER允许转发数据分组的流规则（通过控制通道）从数据路径转发数据分组到控制器（或方向相反的转发）。这就启动了PACKET_IN和PACKET_OUT行为。

OpenFlow的转发模型提供两种模式：主动模式（预先提供）和被动响应模式（数据平面驱动）。在主动模式下，控制程序将先于需求而放置转发表项。如果收到的流不能与现有的流表项匹配，则运行者有两种（全局的）选择：丢弃这个流，或使用PACKET_IN选项来作出决定，以创建适应这些数据分组的流表项（无论是正面的、转发或负面的，还是处置），此即被动响应模式。
控制通道最初被规定为一个对称的TCP会话（可能用TLS来保证安全）。该通道用于配置和管理（放置流表、收集事件以及统计），并提供交换机与控制器/应用程序之间发送和接口分组的路径。
统计数据支持流、聚合、表、端口、队列和厂商特定的计数器。
在OpenFlow协议的1.3版中，允许采用多辅助连接（TCP、UDP、TLS 或DTLS）来处理任何OpenFlow的消息类型或子类型。但UDP和DTLS通道不能保证数据分组的顺序，因此规范里有行为准则来确保对数据分组的特定操作是对称的（以避免在控制器上的顺序问题）。
OpenFlow支持BARRIER消息来创建一个调步机制（创建单元的或流的控制），用于与后续消息有依赖关系的场景（给出的示例是，PACKET_OUT 操作首先需要一个流表项，以匹配数据分组和进行转发）。 

#### 复制

OpenFlow 提供了几种数据分组复制的机制。

ANY和FLOOD预留的虚拟端口主要用于模拟/支持现有协议的行为（例如，LLDP用来为控制器收集拓扑，常采用FLOOD作为其输出端口）。
组表（group table）允许把端口组合成一个输出端口集合，以支持组播、多路径、间接转发和快速故障切换。每个组表实质上是一个动作桶的列表（表面上动作之一是输出到一个出端口）。共有四个组表的类型，但只有下面两个是必需的。

1. All用于组播，列表中的所有动作桶都必须被执行。规范中声称ALL组类型可用于多路径，但这不是IP转发中的多路径，即数据报文将被复制到两条路径。这种行为更加符合提供实况视频，或其他需要在端节点做整流的多路径。
2. Indirect用于模拟IP转发中下一跳的聚合行为，用于更高效的路由聚合。

Apply（ 执行） 动作允许通过创建一个输出/端口动作的列表进行连续的复制（Apply动作在OpenFlow的1.0版中是单例操作）。 

#### FAWG（转发抽象工作组，Forwarding Abstraction Workgroup）

OpenFlow 交换机的模型在基于软件的交换机（在规模和数据分组操控特性上有突出的灵活性），或在符合一些简化假设的硬件转发实体（例如，像TCAM那样有容量、宽度、深度的多入口存储器）上得到很好的支持。但由于不是所有的设备都符合上述条件，所以在OpenFlow的原语、多表以及其他OpenFlow强大功能所支持的数据分组操控方面，设备的支持有非常多的变种。

#### 配置和扩充性（Extensibility）

of-config协议最初设计来设置网元设备上OpenFlow的相关信息（of-config的1.0版本）。该协议是围绕XML模式、Yang数据模型和NETCONF协议来构架的。

----

## SDN控制器

SDN最能引起人们共鸣的三个概念是：可编程、控制平面与数据平面分离，以及用于网络瞬时状态（ephemeral state）管理的集中式控制模型（无论集中程度如何）。

#### 基本概念

一般地说，SDN 控制器是一个提供如下功能的软件系统或者系统的集合。
 
1. 网络状态管理。某些情况下，对于网络状态的管理与分布，有可能需要一个数据库。这些数据库作为知识库，保存来自于被控制的网元设备和相关软件的信息（以及被SDN应用程序所控制的信息，包括网络状态、一些临时配置信息、学习到的拓扑和控制会话信息）。另一些情况下，控制器可能有多个由目的驱动的数据管理进程（例如，关系和非关系数据库）。再有一些情况下，也有可能使用内存型数据库。
2. 高级数据模型。这个数据模型描述被管理的资源、策略和控制器提供的其他服务之间的关系。在很多情况下，这个数据模型可使用YANG建模语言来构建。
3. 一般使用现代的RESTful（REpresentational State Transfer，表征状态转移）API来将控制服务提供给应用程序使用，为主要的控制器和应用程序之间的交互提供便利。理想情况下，API是通过描述控制器服务和特性的数据模型来提供的。在一些情况下，控制器和对应的API是开发环境的一部分，这个开发环境可以从数据模型中产生相应的API代码。一些系统提供一个允许扩展核心功能并为新的模块发布API的开发环境，有些系统甚至支持控制器功能的动态扩展。
4. 安全的控制会话，即控制器和网元设备中相应的代理之间的TCP会话。
5. 一个基于标准的、用于在网元设备上配置应用程序驱动的状态的协议。
6. 一个设备、拓扑和服务发现机制，一个路径计算系统，以及可能的其他网络为中心或者资源为中心的信息服务。

#### 路径计算单元（PCE）服务器

**RSVP-TE问题描述：**
在RSVP-TE网络中，建立TE LSP有两个判断准则：需要的带宽（以及一些其他的约束），和当信令创建LSP标签时的可用带宽。
这里的问题在于，当多个LSP（可能来自于不同的LSR）同时产生LSP信令时，将会竞争相同的资源（即一个特定的节点、链路或者其中的带宽）。当这种情况发生时，LSP建立和保持优先级机制必须被调用，以产生LSP的优先关系。否则，LSP的建立将是基于先到先服务的原则，这将使信令有很大的不确定性。
相反，当LSP信令发出但是其他的LSP已经存在时，LSP抢占机制将被用来抢占低优先级的LSP的资源。
即便利用该机制，在普通和重载的情况下，不同的入口路由器发出LSP信令的顺序也决定了实际被选择的路径。
假设有两个集合的LSP，其中一个集合包含两个优先权为1的LSP（记为A和B），另外一个集合包含两个优先权为2的LSP（记为C和D）。假设当前某个节点上的带宽资源仅仅能够满足一个LSP。这样如果A和B的信令发出，将仅仅只有A和B中的一个LSP被建立，这取决于哪个信令先被发出。如果这时发出C和D的信令，先发出的信令将会抢占A或者B的资源，但是仅仅只有最后发出信令的LSP会最后存在。如果改变发出信令的顺序，就会得到一个不同的结果。
事情就是这样：LSP的优先级与抢占机制的组合，耦合了每个入口路由器的路径选择。
在实践中，这一结果或多或少是期望的结果；然而，由于这种不确定性，导致很难先验地对网络真实行为进行建模。

**Bin-packing（装箱）：**
当一条RSVP LSP的整个路径上的带宽都能满足需求时，才能成功地完成LSP建立。很多时候，即便是在网络整体并不繁忙的情况下，也是无法找到这样的路径的。

```
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@       5Gb        5Gb        3Gb          @
@router1 -> router2 -> router3 -> router5  @
@                       \2Gb       /2Gb    @
@                        ->router4->       @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
```

Gb前的数字代表了链路上的可用带宽。如果想建立从R1到R5的4Gb LSP，由于R3 和R5之间的链路仅仅只有3Gb的带宽，建立过程将失败。然而，R3-R5和R3-R4-R5带宽的总和是5Gb（3+2）。为此，网络中实际会有足够的带宽，但是由于RSVP信令的特性，会导致无法充分利用可用的带宽。于是，这里就产生了一个装箱问题：如何最大化地利用网络中的可用带宽？

**死锁：**
此外，当LSP优先级没有被使用或者同样优先级的LSP发生了冲突时，可能出现死锁或者低效的资源利用。当R1想建立一条3GB的LSP到达R5（通过R1-R2-R3-R5）时，R2同时R2想建立一条2GB的LSP到达R5（通过R2-R3-R5），这时仅有一个会成功。如果R2成功了，R1将找不到到达R5的可用路径。

**PCE解决方案：**
在PCE开发之前，网络运营商为了解决这些问题，使用了复杂的规划工具以找出正确的一组LSP优先级用来获得所需的网络行为，并管理和协调这些LSP的配置，这是一项非常繁重的任务。另外一个方法是超额地提供(Over-provision) 网络带宽，这样就可以避免这些复杂性。
PCE（path computation element，路径计算单元）允许网络运营商将MPLS LSP计算工作委派给一个外部控制器完成。
当和BGP-LS的活动拓扑组合时，网络运营商就可以利用前面提到的复杂工具通过极其简化的配置步骤（通过PCE）来（几乎是实时地）解决这些问题。
PCE环境中有多个组件：一个PCE服务器、一个PCE 客户端（PCC）以及PCE协议（用于在PCE 服务器和PCC 之间交换数据）。
PCE 经历了如下几个阶段的发展。

1. PCE服务器通过无状态的方式管理预先配置LSP；
2. PCE服务器通过有状态的方式管理预先配置LSP；
3. PCE服务器通过有状态的方式管理预先配置和动态创建LSP。

PCE服务器提供三种基础的服务：路径计算、状态维持、基础设施和协议支持。PCE服务器利用PCE协议向网元设备或者PCC传递信息。理想情况下，PCE服务器实际上是一个活动拓扑信息的使用者。虽然还有其他的来源，例如路由协议更新、新的I2RS通用拓扑以及ALTO服务器，但至少部分活动拓扑是从BGP-TE/LS协议中获取的。
随着PCE服务器的发展，路径计算的算法将和其配置代理程序松耦合，例如通过一个核心API将原算法更换为自身设计的算法。这会是一个重要的改进，因为不同客户的商业实践和需求将会促生不同的算法，同时第三方工具也可能促生一些新的算法。

**与理想化的SDN框架之间的关系：**
PCE服务器或者控制器只关注了理想化的SDN框架的很小部分。在这种情况下，尽管它提供了一套RESTful的北向API来提供众多的可编程选项，但是仅仅只使用了单一的南向接口协议PCE-P。这是因为PCE控制器一般只看做是现存控制器的补充。PCE控制器解决方案中的其他组件可能是SDN 控制器的典型组件，例如状态管理、可视化、组件管理、面向应用程序的RESTful API等。对于API，为了和服务编排引擎无缝成，需要包含API转换功能，例如OpenStack Quantum插件。

PCE服务器的原生应用就是创建跨域的、具有明确路径的MPLS-TE隧道。其动机就是为了避免跨运营商的运行障碍，到目前为止，这一点依然是困难重重。PCE服务器可以作为多个运营商的中间点，由于其具有对每一个运营商网络足够的可视性，所以能够建立比仅仅基于本地视图的路由协议更为优化的路径。在骨干网带宽管理上，PCE服务器也有引人注目的案例，例如在现存MPLS LSP 机制上的更加优化的装箱算法。此外，对于接入网，PCE 服务器也可以用于服务管理等功能。
MPLS TED（Traffic Engineering Database，流量工程数据库）在传统的IP/MPLS网络中最开始是作为IGP数据库的扩展被分发的。一般情况下，对MPLS TED的分发终结于区域的边缘，这意味着跨域隧道的明确路径，仅仅只到隧道起点区域的边缘。到边缘之后，因为不知道确定的路径，只能是在ERO中规定一个宽松的跳数。一般情况下，这会导致次优路径。作为这个问题的一个解决方案，BGP-TE/LS通过一个特别的BGP 地址族将TED导出到一个中心式的拓扑存储。中心拓扑存储对各个区域的TED进行整合，允许一个离线应用，基于网络拓扑更加全局的视图，来计算明确的端到端路径。
由于MPLS LSP提供了基于MPLS封装的叠加网络并用于基于MPLS的标签进行流量转发，所以PCE 服务器可以自己或者和其他SDN技术结合起来成为一个SDN 控制器。MPLS LSP信令从路径头部节点通过RSVP-TE发出。通过这种方式，基于PCE的解决方案可以发信令、建立并管理跨多个管理域或者仅是路由区域的LSP隧道。这些隧道可以是更加优化的，或只是根据不同运营商的需要而有所不同的，这是原来因设备没有实现而无法做到的。

----

## 网络可编程性

网络可编程性（network programmability）这一概念作为软件定义网络的关键宗旨之一处于核心地位。网络可编程性的概念存在于网络设备和软件组件之中，或表现为网络设备和软件组件的特征。

#### 管理接口

管理接口可以让网络操作人员在其网络中管理网络设备。这些接口一般为操作者提供一个网络设备的一致的操作视图，包括该网络设备的配置和运行状态。一个管理接口通常由两个关键要素组成：协议和消息格式规范。协议用来描述与发送或接收特定消息（消息由管理器或网元设备生成）相关的语法和语义。这些消息通常包含命令、查询，以及对之前所做查询的响应。在某些情况下，这些消息可以不经查询而直接发出，即为响应网元设备中的一些事件而异步发出事件（通知）。管理接口的另一关键因素是消息的格式和消息的含义。有些管理接口定义可为网络操作人员提供信息目录的数据模型。某些情况下，管理接口也可用于描述管理器如何创建（或安排）它与设备之间的查询或命令。该数据模型通常还描述了系统内可管对象之间的关系。例如，系统的名字可能保存在称为sysName的一个对象中，并关联到一个称为sysUpTime的，给出系统已运行时长的对象。这两个对象都包含在称为system的代表整个系统的父对象中，从而形成关联。 

#### 现代的编程接口

发布-订阅（Publish-Subscriber，一般简称为pub-sub）接口，是一种消息通信模式，即信息的发送者（称为发布者）发送消息给接收者（称为订阅者）。此模式下，发送者并不把消息直接发送到特定的接收者，而是根据所发布消息的特征，把消息划为不同的种类。发布者发布时都不需要知道在什么时间点哪些订阅者存在。在该模式下，订阅者表示对一个或多个类别消息的兴趣，从而只接收那些他们感兴趣的类别的消息。

“可扩展消息与存在协议”（Extensible Messaging and Presence Protocol，XMPP）是发布-订阅式协议的一个例子，它已经被用来实现一些发布-订阅系统。XMPP 是一种基于XML（可扩展标记语言）的通信协议。该协议可用于提供接近实时的即时消息、存在信息，或确需扩展到一个订阅组的任何信息。顾名思义，它是可扩展的，而且实际上已经在过去几年中被多次扩展。

----

## 数据中心概念与结构

服务编排是虚拟化多租户数据中心解决方案的一个重要方面。为了部署和管理多租户数据中心，运营商需要实现某种形式的逻辑上集中化的服务编排。数据中心服务编排提供了逻辑上集中化的控制以及与网络管理员的交互点，是控制其他网络控制器的中心点。从整体来说，服务编排层提供了以下功能：
 
1. 添加删除租户；
2. 服务开通后的账单系统接口；
3. 工作流自动化；
4. 为租户添加删除虚拟机；
5. 指定租户网络的带宽、服务质量（QoS）和安全属性。

----

## 网络功能虚拟化

网络功能虚拟化（Network Function Virtualization，NFV）建立在前面介绍过的几个SDN关键议题之上，这些议题包括控制/数据平面分离、虚拟化、SDN控制器和数据中心概念（特别是编排应用）。

----

## 网络拓扑结构与拓扑信息抽象

控制器需要该信息来规划、配置和监控交换机之间的网络路径。但没有为交换机设置路径前，这个信息是拿不到的，直到为它设置路径才能拿到，也就是说，交换机还在等待控制器在它们的初始化状态中进行编程。链路层发现协议（Link Layer Discovery Protocol，LLDP）是一个行业标准的协议，它允许网络设备在二层局域网内发现并宣告能力与身份的信息。

LLDP允许在协议栈更低层运作的网络设备（例如，二层的网桥和交换机），来学习局域网中网络设备上用于高层协议的一些功能和特性（如IP地址）。
通过LLDP操作收集的信息被存储在网络设备中，并且可以使用SNMP协议、命令行界面或NETCONF 进行查询。一个设备的邻居拓扑和相关联的信息也可以从该数据库中获取。
可以通过LLDP收集的信息包括以下内容：

1. 系统名称和说明；
2. 端口名称和描述；
3. VLAN名称和标识符；
4. IP网络管理地址；
5. 设备的能力（如交换机、路由器或服务器）；
6. MAC地址和物理层信息；
7. 电源信息。

为LLDP操作配置的设备在每个LLDP开启的接口上都发出PDU（协议数据单元）。PDU是按固定时间间隔发送的以太网帧。每个链路层发现PDU 包含一个“类型-长度-值”（type-length-value，TLV）结构的序列，其编码表述前述这些属性4。这些帧被发送给一个不用于转发的特殊组播地址。以防止转发环路导致的广播风暴。

OpenFlow的网络发现使用packet_in和packet_out消息来实现。如前所述，当网络的各端口收到邻居发现信息时，这些信息被交换机通过处理“packet in”规则转给SDN控制器。接着这些信息也被SDN控制器转发给邻居交换机，这样这些邻居就可以学到其MAC地址。重要的是，网络拓扑结构数据库构成了。
前面所述的交换LLDP邻居信息的方法，虽然确实可以解决邻居交换机的拓扑发现问题，但这种方法仍然存在问题。
首先，这种方法仅限于实现LLDP的交换机。这通常倒不是一个大问题，但必须实现一个特定的路由（或交换）协议，这对应用程序来说很没有吸引力。
其次，LLDP拓扑信息局限于交换机的直连二层邻居。如果某些端口配置错误（即它们的初始配置不正确），则这些端口上无法执行发现功能。
最后，在跨越完全由OpenFlow控制的交换机区域、非OpenFlow的区域或混合区的拓扑结构中，邻居发现信息很难缝合在一起。理由是（正如前面所述，控制器的北向API）标准并未统一起来，因此信息的交换仍仅限于理解专有定义的应用程序或其他控制器。进一步看，拓扑格式本身和其所包含的内容也都是专有的。

